<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="keywords" content="machine learning, deep learning,NLP,basic alogrithm">
<meta property="og:type" content="website">
<meta property="og:title" content="qiufengyuyi&#39;s blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="qiufengyuyi&#39;s blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="qiufengyuyi&#39;s blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>qiufengyuyi's blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">qiufengyuyi's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-essayread">
          <a href="/论文总结" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-newspaper-o"></i> <br>
            
            论文总结
          </a>
        </li>
      
        
        <li class="menu-item menu-item-learning">
          <a href="/学习笔记" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br>
            
            学习笔记
          </a>
        </li>
      
        
        <li class="menu-item menu-item-engineering">
          <a href="/工程经验" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-wrench"></i> <br>
            
            工程经验
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/24/tensorflow模型线上部署/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="qiufengyuyi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="qiufengyuyi's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/24/tensorflow模型线上部署/" itemprop="url">tensorflow模型线上部署</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-24T20:01:40+08:00">
                2019-03-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/工程经验/" itemprop="url" rel="index">
                    <span itemprop="name">工程经验</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这次写一个比较短的工程部署总结，说是tensorflow线上部署，并没有使用目前推荐的tensorflow serving。一则是该功能只是整个项目中的一个很小的功能点，如果单独为该功能部署tensorflow serving，成本和时间上会比较超标；二则由于公司内部网络环境限制，无法完整顺利获取tensorflow serving需要的依赖包（在没有网络环境下去装tensorflow serving环境的同学都懂的）；三则，项目并没有对模型在线学习的需求，只需要模型离线训练后，部署到线上即可。基于上述三点条件，选择了使用tensorflow python开发并训练模型，最后将模型进行序列化。然后在java端（项目主开发语言）调用模型进行在线预测。</p>
<h2 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a><strong>前置条件</strong></h2><p>tensorflow 1.3</p>
<p>所需的tensorflow java jar包：libtensorflow-1.4.1.jar</p>
<p>所需的tensorflow jni 库文件：libtensorflow_jni.so  libtensorflow_framework.so</p>
<h2 id="模型序列化"><a href="#模型序列化" class="headerlink" title="模型序列化"></a><strong>模型序列化</strong></h2><p>一开始，由于未考虑模型如何移植到java平台的原因，模型训练和保存的时候，还是按照传统的方式，即通过tf.train.Saver()方法得到saver对象，然后调用saver.save方法保存模型，得到模型的checkpoint,meta,data,index四个文件。</p>
<p>上述文件中保存了模型的中间参数，模型当前训练的状态等信息，在某种意义上是动态的，只能通过tensorflow本身的python接口来调用该保存好的模型，并不能跨平台直接使用。其实模型的本质还是一堆权重数据和具体的权重计算流程，因此需要某种机制能固定住模型的权重数据和计算流程，即freeze模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">saver_predict = tf.train.import_meta_graph(model_config.ckpt_path + model_name)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="keyword">if</span> os.path.exists(model_config.ckpt_path):</span><br><span class="line">             print(<span class="string">"Restoring Variables from Checkpoint"</span>)</span><br><span class="line">             saver_predict.restore(sess, tf.train.latest_checkpoint(model_config.ckpt_path))</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">             print(<span class="string">"Can't find the checkpoint.going to stop"</span>)</span><br><span class="line">             exit()</span><br><span class="line">  output_node_names = [n.name <span class="keyword">for</span> n <span class="keyword">in</span> tf.get_default_graph().as_graph_def().node]</span><br><span class="line">  frozen_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names)</span><br><span class="line">  tf.train.write_graph(frozen_graph_def, model_config.ckpt_path, target_model_path, as_text=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>上述代码的作用是对使用import_meta_graph读取训练好的模型,然后获取当前计算图中的所有节点，并将这些节点中的所有权重参数转化为常量，最后将这些常量保存到一个pb文件中，pb文件即protobuf，是 Google 推出的一种二进制数据交换格式。能够用于跨平台间的数据交换。上述代码实际使用时，会有问题，在java侧使用java的api调用模型时，会出现如下错误：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Invalid argument: Input 0 of node XXXXXXXXXXX/BatchNorm/cond/AssignMovingAvg_1/Switch was passed <span class="built_in">float</span> from XXXXXXXXXXX/BatchNorm/moving_variance:0 incompatible with expected float_ref.</span><br></pre></td></tr></table></figure>
<p>经过一番google，找到了这个github的issue，貌似并没有得到很好的解决，推测问题原因是在freeze模型的权重参数时，对一些tensor的data type处理有问题。问题链接如下，有兴趣的同学可以看看，我最后换了另外一种方式来做。</p>
<p>[]: <a href="https://github.com/davidsandberg/facenet/issues/161" target="_blank" rel="noopener">https://github.com/davidsandberg/facenet/issues/161</a></p>
<p>最终，我使用的是另外一种方法，即在模型训练完时，直接对模型的权重参数序列化，保存为pb文件。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将模型序列化保存`</span></span><br><span class="line">builder = tf.saved_model.builder.SavedModelBuilder(model_config.pb_path.format(epoch))</span><br><span class="line">builder.add_meta_graph_and_variables(sess, [<span class="string">"XXX"</span>])</span><br><span class="line">builder.save()</span><br></pre></td></tr></table></figure>
<p>调用SavedModelBuilder得到builder对象，然后将session中的所有图结构和权重参数存入到builder中，最后保存为pb文件。</p>
<h2 id="Java调用模型在线预测"><a href="#Java调用模型在线预测" class="headerlink" title="Java调用模型在线预测"></a><strong>Java调用模型在线预测</strong></h2><p>这里主要使用的是tensorflow的Java版本api，说是Java版本，其实功能很局限，并没有模型训练方面的功能，所幸它有读取模型和数据，然后在线预测的功能，因此可以适用于当前场景。在部署时，有几点需要注意一下：</p>
<p>1.最基础的事情，当然是记得将tensorflow jar包加入到build-path中。</p>
<p>2.在linux上进行部署时，需要将两个so文件部署到项目工程的java build path中，因为我们的工程中的path包含/usr/lib/，因此可以将两个so文件放到这个路径下。两个so文件主要是用于tensorflow 上层的api与底层操作系统native library进行通信的接口。</p>
<p>下面主要介绍一下如何使用java来调用模型预测。</p>
<p>首先列出用到 两个主要的操作对象：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SavedModelBundle tensorflowModelBundle</span><br><span class="line">Session tensorflowSession</span><br></pre></td></tr></table></figure>
<p>SavedModelBundle为java侧与pb文件接口的对象，能够读取pb文件。而Session对应的是tensorflow中的会话对象，java中，tensorflow的预测操作也是需要在一个会话中进行的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensorflowModelBundle = SavedModelBundle.load(tensorflowModelPath, <span class="string">"XXXX"</span>);</span><br><span class="line">tensorflowSession = tensorflowModelBundle.session();</span><br></pre></td></tr></table></figure>
<p>然后就是构造输入模型的数据了。同python中的情况类似，java侧的模型接收的数据类型必须为tensor类型，因此需要将数据转化为tensor。因此要用到Tensor对象的create方法来生成Tensor，假设当前我们处理好后的数值型输入数据为一个二维数组testvec：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor input = Tensor.create(testvec);</span><br></pre></td></tr></table></figure>
<p>当然如果有其他输入的话，也要都转化为Tensor，简单说就是原来模型中feed_dict中的所有输入都要转化为Tensor对象。</p>
<p>然后就是调用session，输入需要的数据，然后调用具体的计算节点输出结果：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor output = tensorflowSession.runner().feed(<span class="string">"input"</span>,input).feed(XX,XX).fetch(<span class="string">"computation node_name"</span>).run().get(<span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<p>这行代码有几个注意点：</p>
<p>1、feed方法返回的仍然是Runner对象，这个机制使得我们可以链式调用feed方法，将所有需要喂入模型的数据装载。</p>
<p>2、Runner对象的fetch方法是定位到具体的计算图中的计算节点（tensor），这个与python中调用模型预测的方法类似，需要在构造计算图的时候，对模型输出样本预测概率（或者logits）的tensor指定名称。</p>
<p>3、最后的get()方法则是获取返回的结果，这里我输入了参数0，是因为run()方法默认返回的是一个List<tensor>，因为有可能有的需求会调用多个计算节点，因此会返回多个tensor，但是此时我只需要得到一个tensor结果，因此获取List中的第一个元素。</tensor></p>
<p>上述方法返回的是一个Tensor对象，为了输出结果，需要将它转化为原始的二维数据格式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span>[][] resultValues = (<span class="keyword">float</span>[][]) out.copyTo(<span class="keyword">new</span> <span class="keyword">float</span>[<span class="number">1</span>][<span class="number">1</span>]);</span><br></pre></td></tr></table></figure>
<p>调用Tensor的copyTo方法，能够将Tensor转化为指定数据格式的数组。之所以是二维数组，是因为我们的输入数据是二维数组，虽然一次一般是预测一个样本，但为了开发的普适性，统一处理为二维数组，数组存储的就是该样本的预测概率。</p>
<p>最后有一点需要注意一下，在使用完模型后，需要将所有创建的Tensor关闭，销毁资源，当然这个是开发的一个好习惯，能够避免资源的泄露和低效利用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out.close();</span><br><span class="line">input.close();</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

	<div>
      
	</div>
	
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/24/论文笔记系列（一）SGM-for-multi-label-classification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="qiufengyuyi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="qiufengyuyi's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/24/论文笔记系列（一）SGM-for-multi-label-classification/" itemprop="url">论文笔记系列（一）SGM for multi-label classification</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-24T19:22:50+08:00">
                2019-03-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文总结/" itemprop="url" rel="index">
                    <span itemprop="name">论文总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>阅读论文，不能读完就过去了，要思考和记录论文的创新点和有用的思想。这个系列就是以尽可能的简单，尽可能少的文字去将一些核心的东西提取出来，方便自己以后查阅。</p>
<hr>
<p><strong>论文题目</strong>：SGM:Sequence generation model for Multi-label classification</p>
<p><strong>论文target</strong>：文本分类，多标签分类，即一个文本样本分类标签会有多个。</p>
<p><strong>论文intuition</strong>：多标签分类问题中，不同标签之间往往存在着一定的相关关系，使得每个标签并不是独立的。而传统的多标签分类中，通常是在最后一层对每个分类标签使用sigmoid_crossentropy_loss来计算损失，然后将损失求和，同时计算每个分类标签的概率，忽略了标签之间的关联性。比如kaggle上的toxic-classification比赛中，不同类别toxic标签之间的关联性是很大的，比如性别歧视和种族歧视等。</p>
<h2 id="论文主要关注点："><a href="#论文主要关注点：" class="headerlink" title="论文主要关注点："></a>论文主要关注点：</h2><p>1、<strong>使用seq2seq的方式来解决多标签分类问题。</strong>该网络架构本身就很新颖。通过这种方式，能够在一定程度上建模标签之间的关联信息。结构如下：</p>
<p><img src="/2019/03/24/论文笔记系列（一）SGM-for-multi-label-classification/v2-27e4f3cc37818f7f179e794418cc686b_b.png" alt="img"></p>
<p>其实，网络结构主体与经典的带attention的seq2seq是非常相似的。encoder并没有变化，主要改进点在decoder上。由于并没有target文本，我们需要建模的是不同标签之间的关系，因此将所有标签类别作为一个序列，假设有n中标签，那么decoder就有n个时刻。其中，每个时刻t的解码器（假设是一个rnn），一共接受三个不同来源的信息：前一个时刻t-1的rnn hidden state；encoder的attention上下文信息（attention的输入为encoder的隐层信息和decoder当前时刻t的隐层信息）；分类标签的global embedding信息。</p>
<blockquote>
<p><strong>备注： 论文在此处有一个不太对应的地方，在上图中，画出的是每个时刻t，decoder的rnn接收的是当前时刻的 $c_t$ ，但是按照attention本身的使用方法，以及论文中的公式： </strong></p>
<script type="math/tex; mode=display">
s_t = LSTM(s_{t-1},[g(y_{t-1});c_{t-1}])</script><p><strong>应当是先将前一时刻的attention信息和前一时刻的标签global embedding先拼接，然后在输入到rnn中。这与图上的画法不符，只能认为是作者的图画错了。另外，在作者给出的源码中，并没有将c信息与global embedding拼接操作，而是直接将global embedding输入到了rnn中。这个在github上有人提出了issue，但至今没有回应，不知道是什么原因。</strong></p>
</blockquote>
<p>2、<strong>masked softmax以及sorted label。</strong>这个是本文另一个重要的点。decoder中，每个时刻计算得到$s_t$后，如何得到标签呢？需要进行两步操作，第一步原图中并没有详细画出，我就补了一条线，即会在后面接一个类似于全连接层的计算，其接收的输入为当前decoder的$s_t$以及当前时刻计算得到的attention context $c_t$  :</p>
<script type="math/tex; mode=display">
o_t=W_of(W_ss_t+W_cc_t)</script><p>其中 $W_o,W_s,W_c$均为需要学习的权重参数矩阵。而f表示一个non-linear函数。</p>
<p>第二步为masked softmax，即上图中的MS。</p>
<script type="math/tex; mode=display">
y_t=softmax(o_t+I_t)</script><p>使用mask的方式就是对上一步的输出 $o_t$添加一个mask vector $I_t$ ，这个向量的值可是有一定说法的，如果当前时刻输出的标签结果在前面t-1时刻中有出现过，则赋予 $I_t$ 一个极小值，否则则赋予零向量。至于这个极小值，官方源码中是赋予了-9999999999。</p>
<p><strong><em>为什么要使用mask vector？</em></strong>论文说明是为了防止重复预测相同的标签，有时候预测错了标签会因此导致错误一直传递下去，而模型也不希望预测出重复的标签。</p>
<p>至于这样mask有用吗？虽然论文中做了相关的w/o实验，但是由于实验数据本身标签的量级不大，所以个人感觉并不能看出这个做法的有效性。这个还有待后续的验证。</p>
<p>另外还有一个注意点就是sorted label，即训练时，将每个样本的标签按照频率来排序，即出现较多的标签排在序列的较早时刻。这么做的目的在于，我们训练的loss还是使用交叉熵loss，每个时刻上的标签y都需要给定，因此其顺序也要给定。将频率较高的标签放在开头来训练，能够让模型提早学习对数据整体而言最有用的信息，如果一个标签出现次数很少，模型在一开始花了大力气学习它的性价比就不高，容易拖模型的后腿。</p>
<p>3、global embedding。这个可以说是该论文中第二重要的一个点。它的最大作用就是能让每个时刻都能编码记录前面t-1时刻的标签预测进程。传统的做法是直接使用上一时刻预测出来的结果 $y_{t-1}$但是这个结果是通过取所有标签概率分布中最大的那个结果，不一定就是正确的，如果错误，那么就会使这个错误传递。因此论文借鉴了LSTM中的关于门机制的思想，通过门的机制，将前面t-1时刻的所有预测出来的y信息都编码整合。具体做法：</p>
<p>a. 为每个标签初始化一个embedding$e_i$ </p>
<p>b. 根据decoder计算得到的标签的概率分布，以概率为权重，计算所有标签的加权和$\bar{e}$ ：</p>
<script type="math/tex; mode=display">
\bar{e}=\sum_{i}^{l}{P(y_i)e_i}</script><p>c.构建门H:</p>
<script type="math/tex; mode=display">
H=\sigma(W_1e+W_2\bar{e})</script><p>可以看到这个门是由embedding和加权和embedding共同控制的。</p>
<blockquote>
<p>再次吐槽一下，这里论文并没有sigmoid函数的计算，个人认为应当是漏掉了，因为门机制本身就是控制0-1之间的通路的作用，且源码中，是有这一步的操作的。</p>
</blockquote>
<p>d.使用门，计算得到最后的global embedding：</p>
<script type="math/tex; mode=display">
g(y_{t-1})=(1-H)\odot e+H\odot\bar{e}</script><p>注意，这里是向量element-wise乘。</p>
<p>通过上述方式，根据加权和$\bar{e}$ 以及门的控制，能够学习所有标签label的综合信息，防止模型在错误的道路上”一往无前“。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>虽然， 这篇论文写得有一些问题，但是其中有一些思想是可以借鉴的。</p>
<p>1、使用seq2seq来建模多标签之间的相关关系。</p>
<p>2、使用门机制的思想，来综合考虑所有标签的信息，防止对某个标签预测错误的短视。</p>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>
	
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="qiufengyuyi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="qiufengyuyi's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/" itemprop="url">RNN循环神经网络—梯度爆炸和消失的简单解析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-23T22:45:54+08:00">
                2019-03-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习笔记/" itemprop="url" rel="index">
                    <span itemprop="name">学习笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>通过cs224n关于循环神经网络一章的内容，以及自己对其他相关论文和博客的研读后，发现对循环神经网络中BPTT（即backpropagation through time）中，关于产生梯度爆炸和梯度消失的数学推导不是太理解，因此自己翻阅了线性代数中关于雅克比矩阵的相关内容，经过一番推导，终于搞懂其中的原委。故总结一下，若有错误，请各位大牛指正。  </p>
<h2 id="雅克比矩阵"><a href="#雅克比矩阵" class="headerlink" title="雅克比矩阵"></a>雅克比矩阵</h2><p>先百科一下什么是雅克比矩阵。引用维基百科上的定义，the <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics" target="_blank" rel="noopener">matrix</a>) of all first-order <a href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank" rel="noopener">partial derivatives</a> of a <a href="https://en.wikipedia.org/wiki/Vector-valued_function" target="_blank" rel="noopener">vector-valued function</a>。首先，他是一个矩阵，其次矩阵的元素是一个一阶函数的偏导数，最后这个一阶函数的偏导数的对象是一个向量函数。  </p>
<p>举个例子，大家应该就能明白这个定义意思：  </p>
<p>假设有如下函数排列：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-a7810af7fa9aca48da1d780660fc1349_b.jpg" alt="img"></p>
<p>可以将$y_1…y_n$组成一个向量Y，其shape为$n_1$,同理$x_1…x_n$也组成一个向量X，其shape也为,可以$n_1$看到该平方函数就是一个对向量X的一个向量函数，而其雅克比矩阵可以写成如下形式：（公式比较难看，望包涵）</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-fbedab3cee6f409aea97f7eecf81e263_b.jpg" alt="img"></p>
<p>可以看到除了对角线上的所有矩阵元素值都是0，而对角线上的矩阵元素值就是对应y与x的一阶偏导数值。</p>
<h2 id="RNN中的梯度消失和梯度爆炸问题"><a href="#RNN中的梯度消失和梯度爆炸问题" class="headerlink" title="RNN中的梯度消失和梯度爆炸问题"></a>RNN中的梯度消失和梯度爆炸问题</h2><p>RNN的BPTT，很多博客包括中都详细推过了，这里我不做重复说明，我只聚焦到其中的一点，即梯度消失和爆炸的问题探讨。  </p>
<p>首先，我使用一下cs224n中，对该问题的所有notation。  </p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-d853ef053d653e5df2a3f5a6672c8651_b.jpg" alt="img"></p>
<p>该公式表示了RNN的隐藏层的计算过程，其中，h表示隐藏层的输出，W（hh）表示隐藏层到隐藏层的权重矩阵。（是个方阵）在梯度反向传播过程中，需要计算损失函数对W权重矩阵的梯度，可以得到如下公式：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-bf424d87774c37054bbd7f99b0323bfd_b-1553353288995.jpg" alt="img"></p>
<p>t表示时刻，E表示损失函数，该公式表示将所有时刻t的权重偏导数求和，得到这个序列的最终权重偏导，继续使用链式推导，可以得到：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-cf2e15f1fb0200e86646f2f4df1584aa_b.jpg" alt="img"></p>
<p>其中，损失函数E对y的偏导数、y对ht的偏导数，以及h对W的偏导数都能很容易的求得，除了中间的ht对hk的偏导数。我们下面就重点关注这一项的求解。该式子最终可写成：  </p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-c68d5e47c33e2dff6b575bcb5fa9e3ee_b.jpg" alt="img"></p>
<p>可得知，我们最终需要求的是某时刻的隐藏层值h对上一时刻隐藏层值h的偏导数在所有时刻上的和。  </p>
<p>将这个式子再用链式法则拆开一下，令</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-0089f8a12375d64d2bd5140a333cc107_b.jpg" alt="img"></p>
<p>得到：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-25d98747b95233ef71c63b2b1703e310_b.jpg" alt="img"></p>
<p>其实，从上面的式子可以得知，等式右边的两个乘子项分别是两个不同的雅克比矩阵，因为$h_{t-1}$本身是一个向量函数，而$z_t$是对$h_{t-1}$的向量函数，因此分别将两个乘子式化为雅克比矩阵：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-d1ffec2f90132d630b22460408aefa74_b.jpg" alt="img"></p>
<p>这个矩阵怎么求？回想一下我在上一章介绍雅克比矩阵时举的例子，其实可以类比到这个矩阵，其中$h_t$是一个$n_1$维的向量，而$z_t$也是一个$n_1$维的向量，写成函数排列可得：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-21e02e77f04699217b4c4b6af57f25ff_b.jpg" alt="img"></p>
<p>简单的说，就是该雅克比矩阵中，某一行或某一列上，只有一个偏导数是非0的元素，即该矩阵除了对角线元素，其他元素都为0，因此可写成：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-6c65c9a301247a021580afc293bbb1f4_b.jpg" alt="img"></p>
<p>该矩阵是一个对角矩阵，用diag来表示，其中对角相当于一个向量，每个元素是h对z的偏导数，h与z的关系映射函数是我们网络中的激活函数，这里用 $f’(z_t)$表示h对z的偏导，则上述可写成：$diag(f’(z_t))$</p>
<p>现在关注一下另一个雅克比矩阵：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-4ce59c14bb40b3e0a4cc4c1de1b634c4_b.jpg" alt="img"></p>
<p>同样写成函数排列形式：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-cc0a4cdb87cc30c63858bda46e84a7f3_b.jpg" alt="img"></p>
<p>看到这个函数排列式，是不是对上面的雅克比矩阵求解比较清晰了呢？是的，该雅克比矩阵的每个元素都是对应W权重矩阵的对应元素，即</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-5e47c5b8cb8ce8e8a71eb640571a5b12_b.jpg" alt="img"></p>
<p>最终，可得到：</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-b1a1ddc1aaf37468342bbf5d4547b539_b.jpg" alt="img"></p>
<p>可以得知，当序列长度越长，对一个序列进行BPTT，每次时刻多有对</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-4c9ea60c077608bb8ac55faf536a9e3b_b.jpg" alt="img"></p>
<p>的连乘操作，即相当于W权重矩阵的连乘，刚开始的几层可能影响不大，因为连乘较少，但是当越往前传播，W连乘的级数是急剧上升的，若W矩阵初始化不当，小于1或大于1，都将会使得梯度计算朝着接近于0或者无限大的趋势发展。而我们的激活函数sigmoid或tanh，在梯度很大或很小时的曲线都是很平滑的，很容易导致越往后训练，梯度几乎不变。因此产生了梯度消失和梯度爆炸问题。</p>
<p><img src="/2019/03/23/RNN循环神经网络—梯度爆炸和消失的简单解析/v2-2e8467af982d2160c73c0b9304fd5893_b.jpg" alt="img"></p>
<p>reference：</p>
<p>1、cs224n公开课</p>
<p>2、<a href="https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant" target="_blank" rel="noopener">Jacobian matrix and determinant</a></p>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>
	
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">qiufengyuyi</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="http://www.zhihu.com/people/qiu-zhen-yu-87" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-globe"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">qiufengyuyi</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
