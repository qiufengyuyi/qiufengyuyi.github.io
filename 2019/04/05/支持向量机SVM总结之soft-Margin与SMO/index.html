<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">

    

    
    <title>支持向量机SVM总结之soft-Margin与SMO | qiufengyuyi&#39;s blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content="SVM,SMO,soft margin">
    
    <meta name="description" content="上一章节总结了核方法在SVM中的应用，能够在一定程度上解决原数据线性不可分的问题。另外，还有一种方法，相对于核方法来说，也能解决数据的线性不可分问题，它能够让SVM，模型在一定程度上包容不能被正确分类的点，且理解起来比核方法较为简单，这种方法叫做soft-Margin。本章节就对这个soft-margin方法进行探索，同时研究一个经典的SVM的实现算法SMO模型。 Soft-Margin SVMS">
<meta name="keywords" content="SVM,SMO,soft margin">
<meta property="og:type" content="article">
<meta property="og:title" content="支持向量机SVM总结之soft-Margin与SMO">
<meta property="og:url" content="http://yoursite.com/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/index.html">
<meta property="og:site_name" content="qiufengyuyi&#39;s blog">
<meta property="og:description" content="上一章节总结了核方法在SVM中的应用，能够在一定程度上解决原数据线性不可分的问题。另外，还有一种方法，相对于核方法来说，也能解决数据的线性不可分问题，它能够让SVM，模型在一定程度上包容不能被正确分类的点，且理解起来比核方法较为简单，这种方法叫做soft-Margin。本章节就对这个soft-margin方法进行探索，同时研究一个经典的SVM的实现算法SMO模型。 Soft-Margin SVMS">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-100c0a780e08d5a431b5e43b41a2083e_b.jpg">
<meta property="og:updated_time" content="2019-04-05T03:49:03.285Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="支持向量机SVM总结之soft-Margin与SMO">
<meta name="twitter:description" content="上一章节总结了核方法在SVM中的应用，能够在一定程度上解决原数据线性不可分的问题。另外，还有一种方法，相对于核方法来说，也能解决数据的线性不可分问题，它能够让SVM，模型在一定程度上包容不能被正确分类的点，且理解起来比核方法较为简单，这种方法叫做soft-Margin。本章节就对这个soft-margin方法进行探索，同时研究一个经典的SVM的实现算法SMO模型。 Soft-Margin SVMS">
<meta name="twitter:image" content="http://yoursite.com/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-100c0a780e08d5a431b5e43b41a2083e_b.jpg">
    

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
    


</head>
</html>
<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">backlog of a man&#39;s road to AI learning</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/">主页</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/基础算法/">基础算法</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/学习笔记/">学习笔记</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/工程经验/">工程经验</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/比赛总结/">比赛总结</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/论文总结/">论文总结</a></li></ul>
                                    
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/about/index.html">关于</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/学习笔记/">学习笔记</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-支持向量机SVM总结之soft-Margin与SMO" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        支持向量机SVM总结之soft-Margin与SMO
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/" class="article-date">
            <time datetime="2019-04-05T03:26:21.000Z" itemprop="datePublished">2019-04-05</time>
        </a>
    </div>

		

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/SMO/">SMO</a>, <a class="tag-link" href="/tags/SVM/">SVM</a>, <a class="tag-link" href="/tags/soft-margin/">soft margin</a>
    </div>

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <p>上一章节总结了核方法在SVM中的应用，能够在一定程度上解决原数据线性不可分的问题。另外，还有一种方法，相对于核方法来说，也能解决数据的线性不可分问题，它能够让SVM，模型在一定程度上包容不能被正确分类的点，且理解起来比核方法较为简单，这种方法叫做soft-Margin。本章节就对这个soft-margin方法进行探索，同时研究一个经典的SVM的实现算法SMO模型。</p>
<h2 id="Soft-Margin-SVM"><a href="#Soft-Margin-SVM" class="headerlink" title="Soft-Margin SVM"></a>Soft-Margin SVM</h2><p>SVM模型对数据是否线性可分是有要求的。所以有了用核方法将数据映射到高维特征空间上，来提升数据线性可分的可能性。但是总有一种可能是无论怎么映射，终将无法将得到线性可分的数据；另外，有时候样本数据中是存在异常数据点的，如果此时硬是要将所有点分类正确的话，将会导致模型过拟合，对异常数据的鲁棒性就较差。如下图：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-100c0a780e08d5a431b5e43b41a2083e_b.jpg" alt="img"></p>
<p>因此，基于上述问题，可以对我们原来的SVM最优化目标函数使用regularization的机制，增加一个l1的正则化，如下：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-53ebd4612a3b2b16cf93e0e4c222de62_b.jpg" alt="img"></p>
<p>与之前的hard-SVM的优化目标函数对比：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-c730b4a1667c14e7e00109bb69c5dce4_b.jpg" alt="img"></p>
<p>原始情况是当 $y(w^Tx+b)&gt;0$ 时，表示该数据样本分类正确，当 $y(w^Tx+b)<0 $时，表示该数据样本分类错误，现在引入了 $\xi_{i}$ ,若令 $\xi_{i}>1$ ，可以允许模型分错一些数据，不像之前的模型那么“固执”。再看约束条件，现在约束条件要求数据样本的函数间隔小于1就可以了，放宽了要求，但同时对这些样本数据是有一个惩罚的，惩罚的结果就是在目标函数的cost上，再增加$C\xi_{i}$ 的惩罚。参数C是一个<strong>权重控制</strong>参数，它在使得 $||w||^2$ 尽量大（即间隔尽量小，第一章讲解过原理）与保证绝大多数数据样本点的函数间隔至少为1两个要求之间维持一个平衡。</0></p>
<p>接下来就是按照之前解决hard-SVM的套路，推导得到其对偶问题形式。照例，我们写出原式的拉格朗日乘子式：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-4a21dc6198a34ec07bc5349aa47aaa84_b.jpg" alt="img"></p>
<p>对w求偏导，并使偏导为0得到：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-8dc9ca003a88bdaf115e386c71a71e26_b.jpg" alt="img"></p>
<p>对b求偏导，并使偏导为0得到：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-77c60afeac2931d0b6e8178bd32dbcf6_b.jpg" alt="img"></p>
<p>对 $\xi_{i}$ 求偏导，并使偏导为0得到：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-a6805480c9fa53513590c1079546c0d3_b.jpg" alt="img"></p>
<p>将上面所有得到的表达式反代入L中，得到：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-df54aa0f6fbdd54f7018f8e03fdc08c5_b.jpg" alt="img"></p>
<p>因为 $\gamma_{i}=C-\alpha_{i}\geq0 $,所以 $0\leq\alpha_{i}{}\leq C$ 。</p>
<p>因此可以得到带约束条件的对偶问题形式为max(min(L))，即：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-afddce6016b3c4c14c21b54a9ef4df7e_b.jpg" alt="img"></p>
<p>可以看出，这个对偶问题与之前的hard-SVM的对偶问题形式很相似，唯一区别的地方在于 $\alpha_{i}$ 的约束条件不一样了。因此对应的KKT条件也不一样，下面来推导一下这个KKT条件（主要是推导KKT中的补充条款，其他条件很容易就能看出来）。</p>
<p>首先构造 $g_{i}(w)=1-\xi_{i}-y^{(i)}(w^Tx+b)\leq0$ ,根据KKT补充条款中：不等式约束函数与对应的拉格朗日乘子的乘积应当为0，以及原始问题中，同时存在两个不等式约束，因此应有两个KKT补充条件如下：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-4ac454aed0257763d601dfcbeeff83d8_b.jpg" alt="img"></p>
<p>同时我们备注一个概念，即分隔超平面上下两边margin距离为1的区域称为margin内部，而距离大于1的区域称为margin外部。</p>
<ol>
<li>当 $\alpha_{i}=0$ ，此时 $\gamma_{i}=C $ ， $\xi_{i}=0$ ，则没有任何惩罚项，所以 $y^{(i)}(w^Tx+b)\geq1$，满足这个条件的样本点对应的是margin外部两边分类正确的点，不需要惩罚，其中 $y^{(i)}(w^Tx+b)=1$ 的点对应在margin线上的点。</li>
<li>当 $\alpha_{i}=C $， $g_{i}(w)=0$ ，此时 $y^{(i)}(w^Tx+b)=1-\xi_{i}\leq1$ ，满足这个条件的样本点对应的是margin内部分类错误的点，此时是需要对这些点进行惩罚的。</li>
<li>当 $0&lt;\alpha_{i}&lt;C ​$,此时 $g_{i}(w)=0 ​$，又因为 $\gamma_{i}=C-\alpha_{i}\ne0​$ ,因此 $\xi_{i}=0​$ ，所以 $y^{(i)}(w^Tx+b)=1-\xi_{i}=1​$ ，满足这个条件的样本点对应的是在margin先上的点。</li>
</ol>
<h2 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h2><p>SMO，即sequential minimal optimization算法，是由John Platt给出的一种高效率的解决SVM的对偶问题最优化的算法。下面就这个算法总结一下其原理。</p>
<p><strong>Coordinate ascent algorithm</strong></p>
<p>以下简称caa算法。之前了解机器学习的同学肯定知道常用的优化方法有梯度下降法、牛顿法等等。这些方法都是求函数极值解的方法。实际上，目前SVM中需要求解对偶问题的目标函数为一个以 $\alpha_{i} ​$为自变量的函数 $W(\alpha_{1},\alpha_{2},\alpha_{i},…\alpha_{m})​$ ,其中m为样本个数，最终是要求这个函数的极大值即 $max_{\alpha}W​$ ，同时还带有约束条件。在这个问题中，如果我们只对一个参数 $\alpha_{i}​$ 进行优化，其他参数固定为常数，这时对一个参数求极值是比较容易的。这就是caa算法的核心。具体算法如下：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-acb0691c361bbb407a279c7d1690bb49_b.jpg" alt="img"></p>
<p>外层循环表示每次迭代训练直到收敛。而内层循环为对所有样本数据进行循环，每个样本只对其对应的 $\alpha_{i} $进行优化，其他参数固定为常数。</p>
<p>其实这里选择哪个 $\alpha_{i}$ 作为优化目标是有讲究的，在John Platt的论文中给出了一种启发式的选择 $\alpha_{i} $的算法，这个在后面会讲到。</p>
<p>下图描绘了caa算法的一个过程，很容易看到每次迭代优化的方向都是与坐标轴的某个轴平行，这是因为每次我们只优化一个参数。</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-f5b1c697d405093966036199c6031a9e_b.jpg" alt="img"></p>
<p><strong>Platt的SMO</strong></p>
<p>SMO就是使用了caa方法，但是与上述的不同。首先，我们使用上述方法，每次只优化一个参数，其他参数固定。此时假定我们选择 $\alpha_{1}​$为优化目标参数，那么因为有约束条件 $\sum_{i=1}^{m}{\alpha_{i}y^{(i)}}=0​$，所以有 $\alpha_{1}y^{(1)}=-\sum_{i=2}^{m}{\alpha_{i}y^{(i)}} ​$，等式两边同时乘以 $y^{(1)}​$ ，因为 $y^{(1)}\in \{-1,1\}​$ ，所以上述等式可化为： $\alpha_{1}=-y^{(1)}\sum_{i=2}^{m}{\alpha_{i}y^{(i)}}​$ ，由此式可以得到 $\alpha_{1}​$ 其实就是其余参数的线性组合，一旦固定了其他参数，那么 $\alpha_{1}​$ 也就固定了，无法优化。所以只对一个参数优化，固定其他参数是无法进行下去的。因此至少需要一次对两个参数进行优化。因此算法如下：</p>
<p>迭代直到收敛{</p>
<ol>
<li>通过某种算法选择两个参数 $\alpha_{i} $和 $\alpha_{j}$ .</li>
<li>使用 $\alpha_{i}$ 和 $\alpha_{j}$ 为优化目标参数，去优化函数$W(\alpha)$ ,同时固定其他参数为常数。</li>
</ol>
<p>}</p>
<p>由等式约束得到， $\alpha_{1}y^{(1)}+\alpha_{2}y^{(2)}=-\sum_{i=3}^{m}{\alpha_{i}y^{(i)}} $，便于描述，等式右边我们定义一个符号 $\zeta$ 表示一个常数，因此有 $\alpha_{1}y^{(1)}+\alpha_{2}y^{(2)}=\zeta$ ，可以将该函数曲线看做是一条斜率是|1|的一个直线，当斜率为1时，表示y1和y2是异号的。结合 $0\leq\alpha\leq C$ 的约束，可以画出如下函数曲线：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-20914b20ca4291bf83b5cc547b8b299a_b.jpg" alt="img"></p>
<p>可知函数直线与边界相交点，可以得到 $\alpha$ 的上下界分别为：</p>
<p>$H=min(C,C-\alpha_1+\alpha_2)$ ,$L=max(0,\alpha_2-\alpha_1)$ </p>
<p>若斜率为-1，即y1和y2是同号，可画出如下图：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-bbf55baaa11c05f89f649e35b0ef8292_b.jpg" alt="img"></p>
<p>可以得到 $\alpha $的上下界分别为：</p>
<p>$H=min(C,\alpha_1+\alpha_2) ​$， $L=max(0,\alpha_2+\alpha_1-C) $</p>
<p>用 $\alpha_{2}$ 表示 $\alpha_1$ ,得到： $\alpha_1=(\zeta-\alpha_2y^{(2)})y^{(1)}$ ，反代入W中，可以得到一个以 $\alpha_2$ 为自变量的一个一元二次方程形式的表达式： $a\alpha_2^2+b\alpha_2+c$ ,对其求偏导，可以求出 $\alpha_2$ ,要保证满足 $L\leq\alpha_2\leq H$ ，先使用 $\alpha_2^{new,unclipped}$ 表示求导求出来的。然后最终与上下界结合得到的最终参数值应为：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-40dc1875dd725d28e2b5c0acb44a4fd5_b.jpg" alt="img"></p>
<p>同时也把 $\alpha_1^{new} $也可以求出来，由于其余参数是固定不变的，因此old和new的其他参数和应当相同，所以有： $\alpha_1^{new}y^{(1)}+\alpha_2^{new}y^{(2)}=\alpha_1^{old}y^{(1)}+\alpha_2^{old}y^{(2)} ​$,因此 $\alpha_1^{new}=\alpha_1^{old}+(\alpha_2^{old}-\alpha_2^{new})y^{(2)}y^{(1)} $</p>
<p>关键在于求 $\alpha_2^{new,unclipped} $。我们对 $W(\alpha_2)$ 求导，并令导数为0，最终得到表达式：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-a045357fbf7a829c05e61b96fd7ed01f_b.jpg" alt="img"></p>
<p>其中， $E_i=f(x_i)-y^{(i)}​$ ，表示模型预测值和真实值的误差，而K表示对应的数据样本xi与xj的内积使用核方法替换后的值。（具体推导比较繁琐，具体见<a href="http://blog.csdn.net/luoshixian099/article/details/51227754" target="_blank" rel="noopener">【机器学习详解】SMO算法剖析 - CSDN博客</a>）</p>
<p>若K11+K22-2K12=0,则表示样本x1和x2的输入特征相同，其实K11+K22-2K12是 $W(\alpha_2) ​$对 $\alpha_2 ​$的二阶导，因此若K11+K22-2K12=0，表示原函数是一个单调函数，因此是在边界处取极值的。若K11+K22-2K12&lt;0,此时原函数是凸函数，没有极小值，因此也在边界处获得极值。</p>
<p>获取 $\alpha $的值后，相当于获得了w的值，但是b的值仍然需要单独处理，每轮迭代后都要对b值进行更新，因为其影响着 $E_i=f(x_i)-y^{(i)}$ 的计算。</p>
<p>若 $0&lt;\alpha_1^{new}&lt;C $,由KKT补充条款得知， $y^{(1)}(w^Tx+b)=1$ ，因此 $(w^Tx+b)=y^{(1)}$ ，因此 $\sum_{i=1}^{m}{\alpha_iy^{(i)}K_{i1}}+b=y^{(1)}$ ,由此得到:</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-e51c4f1a7656f41e0685237c37a3b5d6_b.jpg" alt="img"></p>
<p>可以将上式再化简，其中：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-3f352c5be3484b2de52b223092da4ba8_b.jpg" alt="img"></p>
<p>因此可得：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-19e9a0e95f481a8e36e673eeacad809b_b.jpg" alt="img"></p>
<p>如果 $0&lt;\alpha_2^{new}&lt;C $，则与上述推导同理，可得：</p>
<p><img src="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-a500cf5a39f97016349194016d79bde1_b.jpg" alt="img"></p>
<p>若两个同时满足 $0&lt;\alpha_i^{new}&lt;C​$ ，则 $b_1^{new}=b_2^{new}​$ 。</p>
<p>若都不满足 $0&lt;\alpha_i^{new}&lt;C$ ，表示参数的值在边界上，此时，b1与b2之间的任何数都满足KKT条件，都可以作为b的更新值，一般取平均。</p>
<p><strong>拉格朗日乘子的启发式选择方法</strong></p>
<p>最后简单讲一下，Platt是如何使用启发式算法来有效率地选择乘子的顺序，使得我们的算法效率最高。</p>
<p>因为有两个参数选择，因此算法的选择也是分为外层循环选第一个参数，然后内层循环选第二个变量。算法的核心思想在于关注那些会违反KKT条件的样本对应的乘子，这些乘子才最需要去优化，而那些本身就符合KKT条件的样本，则不需要优先优化，可以将优先级放低。</p>
<p>选择 $\alpha_1$ :</p>
<ol>
<li>先遍历一次样本数据集，找出所有违反KKT条件的样本对应的乘子，适合优化然后选择第二个参数，见后分析，对这两个变量进行优化。</li>
<li>遍历所有非边界的样本集（ $0&lt;\alpha_i&lt;C​$ ），找出其中违反KKT的参数作为第一个变量，再选择第二个变量，进行优化。</li>
<li>重复步骤1,2，即在整个样本集和非边界样本集上来回切换遍历，寻找违反KKT条件的样本对应的参数。直到遍历整个样本数据集后，找不到违反KKT条件的样本点了，此时推出。</li>
</ol>
<p>选择 $\alpha_2$ :</p>
<p>假设在上述过程中已经挑选了一个参数 $\alpha_1 $，那么我们要找的 $\alpha_2$ 应当是是优化最有效率，即优化后得到的新参数变化越大越好，因为 $\alpha_2$ 依赖于 $|E_1-E_2|$ ，因此 $|E_1-E_2| $越大越好。当$ E_1<0 $，那么选择最大的$ e_i $作为 $e_2$ 是最合适的；若 $e_1>0$ ，那么选择最小的 $E_i$ 作为 $E_2 $是最合适的。</0></p>
<ol>
<li>因为边界上的样本对应的 $\alpha_i=0,\alpha_i=C $，在优化过程中难以优化，所以建议先在非边界数据集上进行上述步骤。</li>
<li>若非边界集上没有，则在整个样本集上选择第二个变量。</li>
<li>若整个样本集没有，则跳入到选择第一个变量的过程。</li>
</ol>
<p>reference:</p>
<p>cs229 notes</p>
<p>林轩田的机器学习公开课讲义</p>
<p><a href="http://blog.csdn.net/luoshixian099/article/details/51227754" target="_blank" rel="noopener">【机器学习详解】SMO算法剖析 - CSDN博客</a>）</p>
<p><a href="http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html" target="_blank" rel="noopener">支持向量机（五）SMO算法 - JerryLead - 博客园</a></p>
<p>后续对SVM的总结会结合sklearn和hinge loss与logistic regression的关系来进行。</p>

        </div>
        <footer class="article-footer">
            



    <a data-url="http://yoursite.com/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/" data-id="cju8d9m4r001fx8ut4ktnqhx5" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "qiufengyuyi"
        },
        "headline": "支持向量机SVM总结之soft-Margin与SMO",
        "image": "http://yoursite.com/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/v2-100c0a780e08d5a431b5e43b41a2083e_b.jpg",
        "keywords": "SVM SMO soft margin",
        "genre": "学习笔记",
        "datePublished": "2019-04-05",
        "dateCreated": "2019-04-05",
        "dateModified": "2019-04-05",
        "url": "http://yoursite.com/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/",
        "description": "上一章节总结了核方法在SVM中的应用，能够在一定程度上解决原数据线性不可分的问题。另外，还有一种方法，相对于核方法来说，也能解决数据的线性不可分问题，它能够让SVM，模型在一定程度上包容不能被正确分类的点，且理解起来比核方法较为简单，这种方法叫做soft-Margin。本章节就对这个soft-margin方法进行探索，同时研究一个经典的SVM的实现算法SMO模型。
Soft-Margin SVMS"
        "wordCount": 264
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    
        
<nav id="article-nav">
    
        <a href="/2019/04/08/EM算法总结/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">下一篇</strong>
        <p class="article-nav-title">
        
            EM算法总结
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2019/04/05/支持向量机SVM总结之核方法/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">支持向量机SVM总结之核方法</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/学习笔记/">学习笔记</a></p>
                            <p class="item-title"><a href="/2019/04/08/PCA算法之特征值分解/" class="title">PCA算法之特征值分解</a></p>
                            <p class="item-date"><time datetime="2019-04-08T12:40:42.000Z" itemprop="datePublished">2019-04-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/学习笔记/">学习笔记</a></p>
                            <p class="item-title"><a href="/2019/04/08/EM算法总结/" class="title">EM算法总结</a></p>
                            <p class="item-date"><time datetime="2019-04-08T12:18:39.000Z" itemprop="datePublished">2019-04-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/学习笔记/">学习笔记</a></p>
                            <p class="item-title"><a href="/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/" class="title">支持向量机SVM总结之soft-Margin与SMO</a></p>
                            <p class="item-date"><time datetime="2019-04-05T03:26:21.000Z" itemprop="datePublished">2019-04-05</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/学习笔记/">学习笔记</a></p>
                            <p class="item-title"><a href="/2019/04/05/支持向量机SVM总结之核方法/" class="title">支持向量机SVM总结之核方法</a></p>
                            <p class="item-date"><time datetime="2019-04-05T03:06:32.000Z" itemprop="datePublished">2019-04-05</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/学习笔记/">学习笔记</a></p>
                            <p class="item-title"><a href="/2019/04/04/支持向量机SVM总结之拉格朗日对偶问题/" class="title">支持向量机SVM总结之拉格朗日对偶问题</a></p>
                            <p class="item-date"><time datetime="2019-04-04T12:34:32.000Z" itemprop="datePublished">2019-04-04</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/基础算法/">基础算法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习笔记/">学习笔记</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程经验/">工程经验</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/比赛总结/">比赛总结</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文总结/">论文总结</a><span class="category-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a><span class="archive-list-count">7</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM/">EM</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HMM/">HMM</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markov-assumption/">Markov assumption</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PCA/">PCA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/">RNN</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SMO/">SMO</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/attention/">attention</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/convex-optimization/">convex optimization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dynamic-programming/">dynamic programming</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kernel-method/">kernel method</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linear-algebra/">linear algebra</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multi-label-text-classification/">multi-label text classification</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paraphrase-identification/">paraphrase identification</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/seq2seq/">seq2seq</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/soft-margin/">soft margin</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/">tensorflow</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/text-classificaton/">text classificaton</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/viterbi/">viterbi</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/EM/" style="font-size: 13.33px;">EM</a> <a href="/tags/HMM/" style="font-size: 20px;">HMM</a> <a href="/tags/Markov-assumption/" style="font-size: 10px;">Markov assumption</a> <a href="/tags/PCA/" style="font-size: 10px;">PCA</a> <a href="/tags/RNN/" style="font-size: 16.67px;">RNN</a> <a href="/tags/SMO/" style="font-size: 10px;">SMO</a> <a href="/tags/SVM/" style="font-size: 20px;">SVM</a> <a href="/tags/attention/" style="font-size: 16.67px;">attention</a> <a href="/tags/convex-optimization/" style="font-size: 10px;">convex optimization</a> <a href="/tags/dynamic-programming/" style="font-size: 13.33px;">dynamic programming</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/kernel-method/" style="font-size: 10px;">kernel method</a> <a href="/tags/linear-algebra/" style="font-size: 10px;">linear algebra</a> <a href="/tags/multi-label-text-classification/" style="font-size: 10px;">multi-label text classification</a> <a href="/tags/paraphrase-identification/" style="font-size: 10px;">paraphrase identification</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/seq2seq/" style="font-size: 16.67px;">seq2seq</a> <a href="/tags/soft-margin/" style="font-size: 10px;">soft margin</a> <a href="/tags/tensorflow/" style="font-size: 13.33px;">tensorflow</a> <a href="/tags/text-classificaton/" style="font-size: 10px;">text classificaton</a> <a href="/tags/viterbi/" style="font-size: 10px;">viterbi</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://www.zhihu.com/people/qiu-zhen-yu-87">zhihu</a>
                    </li>
                
                    <li>
                        <a href="https://github.com/qiufengyuyi">github</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2019 qiufengyuyi</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'http://yoursite.com/2019/04/05/支持向量机SVM总结之soft-Margin与SMO/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
